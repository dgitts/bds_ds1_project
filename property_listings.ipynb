{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When you run this program:\n",
    "* A series of fetch requests will be made to airnda.co to fetch property listings\n",
    "* These property listings will then be merged with an Airbnb dataset obtained online\n",
    "* When this program completes, check the file saved in airbnb_dfw_property_listings variable for all property listings\n",
    "* This program takes about 10 minutes to run\n",
    "\n",
    "#### NOTES:\n",
    "* There is an access_token used to access airdna.co listings. To obtain the token, load an airdna page e.g https://www.airdna.co/vacation-rental-data/app/us/texas/dallas/overview, check XHR traffic in the network tab of browser developer tools and copy the access_token. Paste the value in the access_token variable and record the last updated date. See next point for tip on obtaining access_token.\n",
    "* Tip: Load chromedriver window from airdna_metrics_scraper but do not close window by commenting out the line driver.close(). Only run it for a single market.\n",
    "* If you get a KeyError: 'properties' - update access_token (see above)\n",
    "* city_id_dict was compiled by observing airdna traffic - the index id is an Airdna internal market id for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Airdna property listings...\n",
      "Converting json property lists to csv...\n",
      "Merging csv property lists...\n",
      "Merging Airbnb datasets with Airdna property lists...\n",
      "Completed in 0:09:49.556019 minutes!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "# import time\n",
    "import datetime\n",
    "from datetime import date\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "prop_lists_path = 'data/prop_lists'\n",
    "prop_lists_json_path = prop_lists_path + '/json/'\n",
    "prop_lists_csv_path = prop_lists_path + '/csv/'\n",
    "access_token = 'MjkxMTI|8b0178bf0e564cbf96fc75b8518a5375' # last updated 11/14/20\n",
    "start_year = '2019' # Prop list start year\n",
    "datasets_path = 'data/datasets'\n",
    "airbnb_texas_rental_dataset= datasets_path + '/Airbnb_texas_rental_data.csv'\n",
    "airdna_dfw_property_list = prop_lists_csv_path + '/airdna_dfw_property_list.csv'\n",
    "airbnb_dfw_property_listings = 'data/airbnb_dfw_property_listings.csv'\n",
    "datestamp = date.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "city_id_dict = {\n",
    "    '79752' : 'dallas',\n",
    "    '79888' : 'fort-worth',\n",
    "    '80413' : 'plano',\n",
    "    '80045' : 'irving',\n",
    "    '79491' : 'arlington',\n",
    "    '79901' : 'frisco',\n",
    "    '79949' : 'grand-prairie',\n",
    "    '80237' : 'mckinney',\n",
    "    '79771' : 'denton',\n",
    "    '80482' : 'richardson'\n",
    "}\n",
    "\n",
    "markets = {\n",
    "    'dallas' : 'Dallas',\n",
    "    'fort-worth' : 'Fort-Worth',\n",
    "    'plano' : 'Plano',\n",
    "    'irving' : 'Irving',\n",
    "    'arlington' : 'Arlington',\n",
    "    'frisco' : 'Frisco',\n",
    "    'grand-prairie' : 'Grand Prairie',\n",
    "    'mckinney' : 'McKinney',\n",
    "    'denton' : 'Denton',\n",
    "    'richardson' : 'Richardson'\n",
    "}\n",
    "\n",
    "def setUp():\n",
    "    \"\"\"Initiate folders used for read/write operations\"\"\"\n",
    "    if not os.path.exists(prop_lists_json_path):\n",
    "        os.makedirs(prop_lists_json_path)\n",
    "    if not os.path.exists(prop_lists_csv_path):\n",
    "        os.makedirs(prop_lists_csv_path)\n",
    "\n",
    "def fetch_prop_listings():\n",
    "    \"\"\"Fetch Airdna property listings\"\"\"\n",
    "    print('Fetching Airdna property listings...')\n",
    "    begin_time = datetime.datetime.now()\n",
    "    setUp()\n",
    "    \n",
    "    for city_id, city_name in city_id_dict.items():\n",
    "        url='https://api.airdna.co/v1/market/property_list?access_token={}&city_id={}&start_month=1&start_start_year={}&number_of_months=12&currency=native&show_regions=true'.format(\n",
    "            access_token, city_id, start_year\n",
    "        )\n",
    "        prop_list_json = requests.get(url)\n",
    "        data = prop_list_json.content\n",
    "        file_path = '{}{}_property_list_{}.json'.format(prop_lists_json_path, city_name, datestamp)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(data)\n",
    "\n",
    "    convert_prop_listing_json_data_to_csv()\n",
    "    merge_property_csv_lists()\n",
    "    merge_airbnb_datasets_with_airdna_property_lists()\n",
    "    completion_time = datetime.datetime.now() - begin_time\n",
    "    print('Completed in {} minutes!'.format(completion_time))\n",
    "\n",
    "def convert_prop_listing_json_data_to_csv():\n",
    "    \"\"\"Converts json property listings to csv format\"\"\"\n",
    "    print('Converting json property lists to csv...')\n",
    "    unwanted_prop_keys = ['occ', 'revenue', 'regions', 'id', 'platforms', 'homeaway_property_id', 'm_homeaway_property_id']\n",
    "    for city_id, city_name in city_id_dict.items():\n",
    "        file_path = '{}{}_property_list_{}.json'.format(prop_lists_json_path, city_name, datestamp)\n",
    "        with open(file_path) as f:\n",
    "            data = json.load(f)\n",
    "        property_data = data['properties']\n",
    "        # Clean data and add additional calculated fields\n",
    "        for prop in property_data:\n",
    "            # Additional columns\n",
    "            prop['airbnb_url'] = 'https://www.airbnb.com/rooms/' + str(prop['airbnb_property_id'])\n",
    "            # Check & record if Airbnb listing is active\n",
    "            prop['active_listing'] = 0\n",
    "#             if (requests.head(prop['airbnb_url']).status_code == 200):\n",
    "            if (fetch_http_status_code(prop['airbnb_url']) == 200):\n",
    "                prop['active_listing'] = 1\n",
    "            prop['market'] = markets[city_name]\n",
    "            # Filter out unwanted property keys\n",
    "            for unwanted_prop_key in unwanted_prop_keys:\n",
    "                prop.pop(unwanted_prop_key)\n",
    "\n",
    "        # Write data to csv\n",
    "        csv_file_path = '{}{}_property_list_{}.csv'.format(prop_lists_csv_path, city_name, datestamp)\n",
    "        data_file = open(csv_file_path, 'w', encoding='utf-8', newline='')\n",
    "        csv_writer = csv.writer(data_file)\n",
    "        count = 0\n",
    "\n",
    "        for prop in property_data: \n",
    "            if count == 0: \n",
    "                # Write headers\n",
    "                header = prop.keys() \n",
    "                csv_writer.writerow(header) \n",
    "                count += 1\n",
    "            # Write data \n",
    "            csv_writer.writerow(prop.values()) \n",
    "\n",
    "        data_file.close()\n",
    "\n",
    "def merge_property_csv_lists():\n",
    "    \"\"\"Merge all csv property lists into a single file\"\"\"\n",
    "    print('Merging csv property lists...')\n",
    "#     prop_lists_csv_path = 'prop_lists/csv/'\n",
    "    df = pd.DataFrame()\n",
    "    for city_id, city_name in city_id_dict.items():\n",
    "        file_path = '{}{}_property_list_{}.csv'.format(prop_lists_csv_path, city_name, datestamp)\n",
    "        df = df.append(pd.read_csv(file_path))\n",
    "    df.to_csv(airdna_dfw_property_list, index=False)\n",
    "\n",
    "def merge_airbnb_datasets_with_airdna_property_lists():\n",
    "    \"\"\"Merge Airdna property list and Airbnb dataset into a single file\"\"\"\n",
    "    print('Merging Airbnb datasets with Airdna property lists...')\n",
    "    df1 = pd.read_csv(airbnb_texas_rental_dataset)\n",
    "    df1 = df1[\n",
    "        df1.city.str.contains('Dallas', case=False)\n",
    "        | df1.city.str.contains('Fort Worth', case=False)\n",
    "        | df1.city.str.contains('Plano', case=False)\n",
    "        | df1.city.str.contains('Irving', case=False)\n",
    "        | df1.city.str.contains('Arlington', case=False)\n",
    "        | df1.city.str.contains('Frisco', case=False)\n",
    "        | df1.city.str.contains('Grand Prairie', case=False)\n",
    "        | df1.city.str.contains('McKinney', case=False)\n",
    "        | df1.city.str.contains('Denton', case=False)\n",
    "        | df1.city.str.contains('Richardson', case=False)\n",
    "    ]\n",
    "    df1 = df1[df1.city != 'Lake Dallas']\n",
    "    df1['average_daily_rate'] = df1['average_daily_rate'].str.replace('$', '')\n",
    "    df1['city'] = df1['city'].str.replace('Fort Worth', 'Fort-Worth', case=False)\n",
    "    df1['bedrooms'] = df1['bedrooms'].str.replace('Studio', '0')\n",
    "#     df1.head()\n",
    "    df2 = pd.read_csv(airdna_dfw_property_list)\n",
    "    df2 = df2.rename(columns={'market': 'city', 'adr': 'average_daily_rate', 'airbnb_url' : 'url'})\n",
    "    df2['average_daily_rate'] = round(df2['average_daily_rate'])\n",
    "#     df2.head()\n",
    "    df3 = pd.concat([df2, df1], ignore_index=True)\n",
    "    df3.to_csv(airbnb_dfw_property_listings, index = False)\n",
    "\n",
    "def fetch_http_status_code(url):\n",
    "    \"\"\"Fetch http status code\"\"\"\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=3, backoff_factor=0.5)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    response = session.get(url)\n",
    "    return response.status_code\n",
    "\n",
    "fetch_prop_listings()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
